{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "from grid2op.Reward import L2RPNReward\n",
    "\n",
    "# from l2rpn_baselines.utils import TrainingParam\n",
    "# from l2rpn_baselines.DuelQLeapNet import train \n",
    "# from l2rpn_baselines.DuelQLeapNet.LeapNet_NNParam import LeapNet_NNParam\n",
    "from l2rpn_baselines.utils import TrainingParam\n",
    "from mnet import train \n",
    "from mnet.LeapNet_NNParam import LeapNet_NNParam\n",
    "\n",
    "import grid2op\n",
    "from lightsim2grid.LightSimBackend import LightSimBackend\n",
    "\n",
    "import pathlib\n",
    "\n",
    "from grid2op.Reward import L2RPNSandBoxScore, L2RPNReward\n",
    "from l2rpn_baselines.DuelQLeapNet import evaluate\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import inspect\n",
    "#lines = inspect.getsource(DeepQAgent)\n",
    "#print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the environment\n",
    "# env = grid2op.make(\"l2rpn_case14_sandbox\",\n",
    "#                    reward_class=L2RPNReward)\n",
    "backend = LightSimBackend()\n",
    "env = grid2op.make(\"l2rpn_neurips_2020_track1_large\", backend=backend,\n",
    "                   reward_class=L2RPNReward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathic = pathlib.Path().absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the default training parameters\n",
    "tp = TrainingParam()\n",
    "\n",
    "# this will be the list of what part of the observation I want to keep\n",
    "# more information on https://grid2op.readthedocs.io/en/latest/observation.html#main-observation-attributes\n",
    "li_attr_obs_X = [\"day_of_week\", \"hour_of_day\", \"minute_of_hour\", \"prod_p\", \"prod_v\", \"load_p\", \"load_q\",\n",
    "                 \"actual_dispatch\", \"target_dispatch\", \"topo_vect\", \"time_before_cooldown_line\",\n",
    "                 \"time_before_cooldown_sub\", \"rho\", \"timestep_overflow\", \"line_status\"]\n",
    "\n",
    "# neural network architecture\n",
    "li_attr_obs_X = [\"day_of_week\", \"hour_of_day\", \"minute_of_hour\", \"prod_p\", \"prod_v\", \"load_p\", \"load_q\",\n",
    "                 \"actual_dispatch\", \"target_dispatch\", \"topo_vect\", \"time_before_cooldown_line\",\n",
    "                 \"time_before_cooldown_sub\", \"timestep_overflow\", \"line_status\", \"rho\"]\n",
    "# compared to the other baseline, we have different inputs at different place, this is how we split it\n",
    "li_attr_obs_Tau = [\"rho\", \"line_status\"]\n",
    "#sizes = [800, 800, 800, 494, 494, 494]\n",
    "sizes = [1800, 1800, 1800, 994, 994, 994]\n",
    "\n",
    "\n",
    "# nn architecture\n",
    "x_dim = LeapNet_NNParam.get_obs_size(env, li_attr_obs_X)\n",
    "tau_dims = [LeapNet_NNParam.get_obs_size(env, [el]) for el in li_attr_obs_Tau]\n",
    "\n",
    "kwargs_archi = {'sizes': sizes,\n",
    "                'activs': [\"relu\" for _ in sizes],\n",
    "                'x_dim': x_dim,\n",
    "                'tau_dims': tau_dims,\n",
    "                'tau_adds': [0.0 for _ in range(len(tau_dims))],  # add some value to taus\n",
    "                'tau_mults': [1.0 for _ in range(len(tau_dims))],  # divide by some value for tau (after adding)\n",
    "                \"list_attr_obs\": li_attr_obs_X,\n",
    "                \"list_attr_obs_tau\": li_attr_obs_Tau\n",
    "                }\n",
    "\n",
    "# select some part of the action\n",
    "# more information at https://grid2op.readthedocs.io/en/latest/converter.html#grid2op.Converter.IdToAct.init_converter\n",
    "kwargs_converters = {\"all_actions\": None,\n",
    "                     \"set_line_status\": False,\n",
    "                     \"change_bus_vect\": True,\n",
    "                     \"set_topo_vect\": False\n",
    "                     }\n",
    "# define the name of the model\n",
    "nm_ = \"FirstDQLN\"\n",
    "save_path = f'{pathic}'\n",
    "logs_dir = f'{pathic}/LOGS'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* посмотреть на данные попоробовать отскейлить. Т.к. ошибка слишком большая.\n",
    "* Уменьшить LR\n",
    "* Добавить механизм внимания\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Reloading a model, the architecture parameters will be ignored\n",
      "INFO: Reloading a model, training parameters will be ignored\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method LtauBis.call of <l2rpn_baselines.DuelQLeapNet.DuelQLeapNet_NN.LtauBis object at 0x7f9eee670dd8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method LtauBis.call of <l2rpn_baselines.DuelQLeapNet.DuelQLeapNet_NN.LtauBis object at 0x7f9eee670dd8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/efimovin/L2RPN_large\" target=\"_blank\">https://app.wandb.ai/efimovin/L2RPN_large</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/efimovin/L2RPN_large/runs/l9lqjx0x\" target=\"_blank\">https://app.wandb.ai/efimovin/L2RPN_large/runs/l9lqjx0x</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9ee80a8518>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method TensorFlowOpLayer._defun_call of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f9ee80a8518>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train(env,\n",
    "          name=nm_,\n",
    "          iterations=10000000, #bad realisation\n",
    "          save_path=save_path,\n",
    "          load_path=save_path,  #If you want to reload your baseline, specify the path where it is located. **NB** if a baseline is reloaded\n",
    "                                # some of the argument provided to this function will not be used.\n",
    "          logs_dir=logs_dir,\n",
    "          training_param=tp,\n",
    "          kwargs_converters=kwargs_converters,\n",
    "          kwargs_archi=kwargs_archi);\n",
    "except Exception as e:\n",
    "    print(f'{e}!!!!!!')\n",
    "finally:\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree(f'{pathic}/LOGS')\n",
    "shutil.rmtree(f'{pathic}/wandb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = LightSimBackend()\n",
    "env = grid2op.make(\"l2rpn_neurips_2020_track1_large\", backend=backend,\n",
    "                   reward_class=L2RPNReward)\n",
    "\n",
    "\n",
    "# Call evaluation interface\n",
    "evaluate(env,\n",
    "         name=nm_,\n",
    "         load_path=save_path,\n",
    "         logs_path=logs_dir,\n",
    "         nb_episode=100,\n",
    "         nb_process=1,\n",
    "         max_steps=-1,\n",
    "         verbose=False,\n",
    "         save_gif=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
